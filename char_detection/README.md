# cv_pytorch_learn

### 一　python虚拟环境使用

#### 1.1 虚拟环境

本地创建和使用一个虚拟环境，pip list可以看到，系统里python下面的很多包在虚拟环境里都没有

```
python3.7 -m venv py37_cv　新建
source py37_cv/bin/activate　激活
deactivate　退出
pip freeze > requirements.txt　打包新安装的包版本
pip install -r requirements.txt　在另一台机器上新建虚拟环境，复制上一个环境
```



#### 1.2 Docker



### 二　天池比赛  不定长街景字符编码识别（代码在char_detection文件夹里）

**赛题目的：**识别图片中的街道字符编码

**赛题数据集：**数据采用公开数据集SVHN街道字符，并进行了匿名采样处理，训练集数据包括3W张照片，验证集数据包括1W张照片。

**数据集标签：**需要注意的是本赛题需要选手识别图片中所有的字符，为了降低比赛难度，提供了训练集、验证集和测试集中所有字符的位置框，数据集标签采用json文件保存。对于训练数据每张图片将给出对于的编码标签，和具体的字符框的位置（训练集、测试集和验证集都给出字符位置），可用于模型训练：

| Field  | Description                |      |
| ------ | -------------------------- | ---- |
| top    | 左上角坐标X                |      |
| height | 字符高度                   |      |
| left   | 左上角坐标Y                |      |
| width  | 字符宽度                   |      |
| label  | 字符编码（每个数字的真值） |      |



学员手册：https://shimo.im/docs/ne3VVNlN1Js8FB3b/read

课程内容、任务及baseline：　https://github.com/datawhalechina/team-learning/tree/master/03%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%



### Task 1 赛题思路和数据集熟悉

#### 1.1 虚拟环境及依赖包的安装，及baseline的运行步骤

１）可以先创建虚拟环境，然后执行下面指令复现环境

pip install -r requirements.txt

２）download_dataset.py　可以从云端下次数据集

３）json_load.py　可以读一张图片然后根据json文件里的label把数字扣出来

４）baseline.py　可以训练模型，然后输出识别结果到.csv文件(可以WPS打开)里

#### 1.2 pytorch源码学习

Pytorch Sampler详解(界面动画很赞)：　https://www.cnblogs.com/marsggbo/p/11541054.html  

DataLoader源码阅读：　https://blog.csdn.net/u012436149/article/details/78545766 

#### 1.3 解题思路

赛题本质是分类问题，需要对图片的字符进行识别。本次赛题的难点是需要对不定长的字符进行识别，与传统的图像分类任务有所不同。

**简单入门思路：**定长字符识别，填充字符长度到定长

**专业字符识别思路：**不定长字符识别，比较典型的有CRNN字符识别模型，可以视为单词或句子

**专业分类思路：**检测再识别  

在赛题数据中已经给出了训练集、验证集中所有图片中字符的位置，因此可以首先将字符的位置进行识别，利用物体检测的思路完成。此种思路需要参赛选手构建字符检测模型，对测试集中的字符进行识别。选手可以参考物体检测模型SSD或者YOLO来完成。 



### Task 2　图像读取和数据扩增（Data Augmentation）的理解

#### 2.1 图像读取

由于赛题数据是图像数据，赛题的任务是识别图像中的字符。因此我们首先需要完成对数据的读取操作，在Python中有很多库可以完成数据读取的操作，比较常见的有Pillow(RGB)和OpenCV(BGR格式，貌似需要转成RGB才能显示).

**Pillow：**有很多图像操作，是图像处理的必备库。       
Pillow的官方文档：https://pillow.readthedocs.io/en/stable/

**OpenCV：**包含了众多的图像处理的功能，OpenCV包含了你能想得到的只要与图像相关的操作。此外OpenCV还内置了很多的图像特征处理算法，如关键点检测、边缘检测和直线检测等。       
OpenCV官网：https://opencv.org/       
OpenCV Github：https://github.com/opencv/opencv      
OpenCV 扩展算法库：https://github.com/opencv/opencv_contrib

**matplotlib：**可以用来绘图，显示图片

#### 2.2 数据扩增（Data Augmentation）

在深度学习中数据扩增方法非常重要，数据扩增可以增加训练集的样本，同时也可以有效**缓解模型过拟合**的情况，也可以给模型带来的**更强的泛化能力**。

数据扩增方法有很多：从颜色空间、尺度空间到样本空间，同时根据不同任务数据扩增都有相应的区别。        
对于图像分类，数据扩增一般不会改变标签；对于物体检测，数据扩增会改变物体坐标位置；对于图像分割，数据扩增会改变像素标签。     

几何变换：可以对抗数据中的视角偏差、尺寸偏差；

灰度和彩色空间变换：对抗数据中的光照、色彩、亮度的偏差；

添加噪声和滤波：应对噪声干扰，帮助CNN学习更泛化的特征。噪声：高斯噪声、椒盐噪声；滤波：模糊、锐化。

图像混合

随机擦除Random erasing

##### 2.2.1 常用的数据扩增库     

- #### torchvision      

  https://github.com/pytorch/vision      
  pytorch官方提供的数据扩增库，提供了基本的数据数据扩增方法，可以无缝与torch进行集成；但数据扩增方法种类较少，且速度中等；       

- #### imgaug         

  https://github.com/aleju/imgaug      
  imgaug是常用的第三方数据扩增库，提供了多样的数据扩增方法，且组合起来非常方便，速度较快；      

- #### albumentations       

  https://albumentations.readthedocs.io      
  是常用的第三方数据扩增库，提供了多样的数据扩增方法，对图像分类、语义分割、物体检测和关键点检测都支持，速度较快。      

#### 2.3 Pytorch读取数据 

在Pytorch中数据是通过Dataset进行封装，并通过DataLoder进行并行读取。

我们在定义好的Dataset基础上构建DataLoder，你可以会问有了Dataset为什么还要有DataLoder？其实这两个是两个不同的概念，是为了实现不同的功能。                 

- Dataset：对数据集的封装，提供索引方式的对数据样本进行读取      
- DataLoder：对Dataset进行封装，提供批量读取的迭代读取    

在加入DataLoder后，数据按照批次获取，每批次调用Dataset读取单个样本进行拼接（　<u>**这一步一开始没看懂**</u>　）。其实，dataset里存的就是读到的每张图片和对应的标签，dataloader里存的是读到的每批(batch)图片和对应的标签（方便用多线程的方式读取和处理）。此时data的格式为：      

```
代码：

for data in train_loader:
	break
[img, label] = data
print(img.size(), label.size())

打印结果：
```

​                ``` torch.Size([10, 3, 64, 128]), torch.Size([10, 6]) ```          
data里面有两个字段，前者为图像文件，为batchsize * chanel * height * width次序；后者为字符标签，为batchsize * labelsize。      

### Task 3 字符识别模型、分类模型

#### 3.1 早期图像分类模型

参数太多，不适用图像数据

1. K 近邻（k-nearest neighbor）：根据k近邻的类别确定该点的所属类别
2. 线性分类（Linear classifier）：输入通过一个矩阵线性变换到另外一个空间，输入是图片，输出是类别。f(x,W)=Wx+b，关键就是确定W矩阵和偏置b
3. 多层感知机（MLP）:多层线性分类器，可以简单的理解为一个神经网络（Neural Network）

#### 3.2  CNN（卷积神经网络）中的概念

卷积过程：卷积核在原图像中，按照确定的步长(stride)和对原图像周围填充(padding)，从左到右从上到下的依次滑动，然后每一次移动相乘相加作为输出

最大池化层：卷积过程中，卷积步长为1，每一次移动选取卷积核中最大的元素作为输出。也叫下采样，可以减小图片大小

激活函数：Relu，引入非线性因素，让网络的可表达性更强

全连接层：线性变换，将图像的像素对应为类别的数字

softmax层：将任意数字变换为0~1间的概率

#### 3.3 CNN图像分类模型

LeNet：1998，5*5的卷积核

AlexNet：2012，输入227\*227\*3 RGB图像，96组11*11的卷积核

VGG：2014

GoogleNet：2014

ResNet（残差块）：2015

ResNet要解决的问题：网络越深，误差越大。这不是过拟合的问题，是优化问题，网络越深，越难优化

解决：将前面的学习的内容copy到后面



### Task 4 模型训练与验证

#### 4.1 过拟合（Overfitting）和 验证集的划分

​		在机器学习模型（特别是深度学习模型）的训练过程中，模型是非常容易过拟合的。深度学习模型在不断的训练过程中**训练误差**会逐渐降低，但**测试误差**的走势则不一定。       
　　在模型的训练过程中，模型只能利用**训练数据**来进行训练，模型并不能接触到**测试集**上的样本。因此模型如果将训练集学的过好，模型就会记住训练样本的细节，导致模型在测试集的泛化效果较差，这种现象称为过拟合（Overfitting）。与过拟合相对应的是欠拟合（Underfitting），即模型在训练集上的拟合效果较差。      

　　随着模型复杂度和模型训练轮数的增加，CNN模型在训练集上的误差会降低，但在测试集上的误差会逐渐降低，然后逐渐升高，而我们为了追求的是模型在测试集上的精度越高越好。                
　　导致模型过拟合的情况有很多种原因，其中最为常见的情况是**模型复杂度（Model Complexity ）太高**，导致模型学习到了训练数据的方方面面，学习到了一些细枝末节的规律。

　　解决上述问题最好的解决方法：构建一个与测试集尽可能分布一致的样本集（可称为**验证集**），在训练过程中不断验证模型在验证集上的精度，并以此控制模型的训练。

从训练集**划分验证集**有如下几种方式：  

- #### 留出法（Hold-Out）           

  直接将训练集划分成两部分，新的训练集和验证集。这种划分方式的优点是最为直接简单；缺点是只得到了一份验证集，有可能导致模型在验证集上过拟合。留出法应用场景是数据量比较大的情况。     

- #### 交叉验证法（Cross Validation，CV）      

  将训练集划分成K份，将其中的K-1份作为训练集，剩余的1份作为验证集，循环K训练。这种划分方式是所有的训练集都是验证集，最终模型验证精度是K份平均得到。这种方式的优点是验证集精度比较可靠，训练K次可以得到K个有多样性差异的模型；CV验证的缺点是需要训练K次，不适合数据量很大的情况。     

- #### 自助采样法（BootStrap）      

  通过有放回的采样方式得到新的训练集和验证集，每次的训练集和验证集都是有区别的。这种划分方式一般适用于数据量较小的情况。      

#### 4.2 调参和优化思路

1. base_line尽可能简单，方便二分定位问题，是数据集的问题 还是网络模型的问题

2. 优化的时候，遵循单一变量原则，选择主要矛盾去优化；简单模型节省时间，先使用简单模型跑通，（损失降低精度提升）调试到一个极限后最后再去变更模型

3. 优化的一个点，动态的改变学习率，当训练到一定程度，改变学习率，可以更快更好的得到训练结果。

   optimizer = torch.optim.Adam(model.parameters(), 0.001) 这里的0.001就是学习率；并且Adam和SGD相比，对学习率的初始值要求不高，可以动态调整



### Task 5 模型集成

#### 5.1 集成学习方法           

在机器学习中的集成学习可以在一定程度上提高预测精度，常见的集成学习方法有Stacking、Bagging和Boosting，同时这些集成学习方法与具体验证集划分联系紧密。         
                 
由于深度学习模型一般需要较长的训练周期，如果硬件设备不允许建议选取留出法，如果需要追求精度可以使用交叉验证的方法。 

#### 5.2 深度学习中的集成学习  

##### 5.3.1 Dropout                

Dropout可以作为训练深度神经网络的一种技巧。在每个训练批次中，通过随机让一部分的节点停止工作。同时在预测的过程中让所有的节点都其作用。   

Dropout经常出现在在先有的CNN网络中，可以有效的缓解模型过拟合的情况，也可以在预测时增加模型的精度。   

##### 5.3.2 TTA        

测试集数据扩增（Test Time Augmentation，简称TTA）也是常用的集成学习技巧，数据扩增不仅可以在训练时候用，而且可以同样在预测时候进行数据扩增，对同一个样本预测三次，然后对三次结果进行平均。      

##### 5.3.3 Snapshot               

假设我们训练了10个CNN则可以将多个模型的预测结果进行平均。但是加入只训练了一个CNN模型，如何做模型集成呢？          
                   
在论文Snapshot Ensembles中，作者提出使用cyclical learning rate进行训练模型，并保存精度比较好的一些checkopint，最后将多个checkpoint进行模型集成。       

#### 5.3 总结

- 集成学习只能在一定程度上提高精度，并需要耗费较大的训练时间，因此建议先使用提高单个模型的精度，再考虑集成学习过程；
- 具体的集成学习方法需要与验证集划分方法结合，Dropout和TTA在所有场景有可以起作用。

### 本次学习总结

本次学习主要涉及到一些CNN的图像**分类**网络，后续可以继续学习**目标检测**网络方面的知识。

还有一些复杂模型可以深入研究：字符识别模型CTPN，目标检测模型faster-rcnn、yolo。

工具：tensorboardX 可以绘制pytorch里的学习曲线